// Copyright 2018 Google Inc.
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//     http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.
//
// Modifications Copyright 2020-2023 ONDEWO GmbH
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//     http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

syntax = "proto3";

package ondewo.nlu;

import "google/api/annotations.proto";
import "google/protobuf/empty.proto";
import "google/protobuf/field_mask.proto";
import "google/protobuf/struct.proto";
import "google/protobuf/timestamp.proto";
import "google/rpc/status.proto";
import "google/type/latlng.proto";
import "ondewo/nlu/common.proto";
import "ondewo/nlu/context.proto";
import "ondewo/nlu/intent.proto";
import "ondewo/nlu/entity_type.proto";

option cc_enable_arenas = true;
option csharp_namespace = "Google.Cloud.Dialogflow.V2";
option go_package = "google.golang.org/genproto/googleapis/cloud/dialogflow/v2;dialogflow";
option java_multiple_files = true;
option java_outer_classname = "SessionProto";
option java_package = "com.google.cloud.dialogflow.v2";
option objc_class_prefix = "DF";

// A session represents an interaction with a user. You retrieve user input
// and pass it to the [DetectIntent][google.cloud.dialogflow.v2.Sessions.DetectIntent] (or
// [StreamingDetectIntent][google.cloud.dialogflow.v2.Sessions.StreamingDetectIntent]) method to determine
// user intent and respond.
service Sessions {

    // Processes a natural language query and returns structured, actionable data
    // as a result. This method is not idempotent, because it may cause contexts
    // and session entity types to be updated, which in turn might affect
    // results of future queries.
    rpc DetectIntent (DetectIntentRequest) returns (DetectIntentResponse) {
        option (google.api.http) = {
            post: "/v2/{session=projects/*/agent/sessions/*}:detectIntent"
            body: "*"
        };
    }

    // Processes a natural language query in audio format in a streaming fashion
    // and returns structured, actionable data as a result. This method is only
    // available via the gRPC API (not REST).
    rpc StreamingDetectIntent (stream StreamingDetectIntentRequest) returns (stream StreamingDetectIntentResponse);

    // *** SESSION RELATED ENDPOINTS *** //
    // ListSessions: returns list of sessions from ondewo-kb; by default returns only session IDs
    rpc ListSessions (ListSessionsRequest) returns (ListSessionsResponse) {
        option (google.api.http) = {
            get: "/v2/{parent=projects/*/agent}/sessions"
        };
    };

    // GetSession: returns a session(=conversation) from ondewo-kb
    rpc GetSession (GetSessionRequest) returns (Session) {
        option (google.api.http) = {
            get: "/v2/{session_id=projects/*/agent/sessions/*}"
        };
    };

    // CreateSession: creates and returns a session(=conversation) from ondewo-kb
    rpc CreateSession (CreateSessionRequest) returns (Session) {
        option (google.api.http) = {
            post: "/v2/{parent=projects/*/agent}/sessions"
            body: "*"
        };
    };

    // CreateSessionStep: creates a new session step for a session
    rpc CreateSessionStep (CreateSessionStepRequest) returns (SessionStep) {};

    // GetSessionStep: gets an existing session step of a session
    rpc GetSessionStep (GetSessionStepRequest) returns (SessionStep) {
        option (google.api.http) = {
            post: "/v2/{session_id=projects/*/agent/sessions/*}:getSessionStep"
            body: "*"
        };
    };

    // UpdateSessionStep: updates an existing session step in a session
    rpc UpdateSessionStep (UpdateSessionStepRequest) returns (SessionStep) {
        option (google.api.http) = {
            post: "/v2/{session_id=projects/*/agent/sessions/*}:updateSessionStep"
            body: "*"
        };
    };

    // DeleteSessionStep: deletes an existing session step from the session
    rpc DeleteSessionStep (DeleteSessionStepRequest) returns (google.protobuf.Empty) {
        option (google.api.http) = {
            post: "/v2/{session_id=projects/*/agent/sessions/*}:deleteSessionStep"
            body: "*"
        };
    };

    // DeleteSession: delete a session(=conversation) from ondewo-kb (for testing only)
    rpc DeleteSession (DeleteSessionRequest) returns (google.protobuf.Empty) {
        option (google.api.http) = {
            delete: "/v2/{session_id=projects/*/agent/sessions/*}"
        };
    };

    // *** SESSION-LABEL RELATED ENDPOINTS *** //
    rpc ListSessionLabels (ListSessionLabelsRequest) returns (ListSessionLabelsResponse) {
        option (google.api.http) = {
            get: "/v2/{session_id=projects/*/agent/sessions/*}/labels"
        };
    };

    rpc ListSessionLabelsOfAllSessions (ListSessionLabelsOfAllSessionsRequest) returns (ListSessionLabelsResponse) {
        option (google.api.http) = {
            get: "/v2/{parent=projects/*/agent}/sessions/labels"
        };
    };

    rpc ListLanguageCodesOfAllSessions (ListLanguageCodesOfAllSessionsRequest) returns (ListLanguageCodesResponse) {
        option (google.api.http) = {
            get: "/v2/{parent=projects/*/agent}/sessions/language_codes"
        };
    };

    rpc ListMatchedIntentsOfAllSessions (ListMatchedIntentsOfAllSessionsRequest) returns (ListMatchedIntentsResponse) {
        option (google.api.http) = {
            get: "/v2/{parent=projects/*/agent}/sessions/matched_intents"
        };
    };

    rpc ListMatchedEntityTypesOfAllSessions (ListMatchedEntityTypesOfAllSessionsRequest) returns (ListMatchedEntityTypesResponse) {
        option (google.api.http) = {
            get: "/v2/{parent=projects/*/agent}/sessions/matched_entity_types"
        };
    };

    rpc ListUserIdsOfAllSessions (ListUserIdsOfAllSessionsRequest) returns (ListUserIdsResponse) {
        option (google.api.http) = {
            get: "/v2/{parent=projects/*/agent}/sessions/user_ids"
        };
    };

    rpc ListIdentifiedUserIdsOfAllSessions (ListIdentifiedUserIdsOfAllSessionsRequest) returns (ListIdentifiedUserIdsResponse) {
        option (google.api.http) = {
            get: "/v2/{parent=projects/*/agent}/sessions/identified_user_ids"
        };
    };

    rpc ListTagsOfAllSessions (ListTagsOfAllSessionsRequest) returns (ListTagsResponse) {
        option (google.api.http) = {
            get: "/v2/{parent=projects/*/agent}/sessions/tags"
        };
    };

    rpc ListInputContextsOfAllSessions (ListInputContextsOfAllSessionsRequest) returns (ListInputContextsResponse) {
        option (google.api.http) = {
            get: "/v2/{parent=projects/*/agent}/sessions/input_contexts"
        };
    };

    rpc ListOutputContextsOfAllSessions (ListOutputContextsOfAllSessionsRequest) returns (ListOutputContextsResponse) {
        option (google.api.http) = {
            get: "/v2/{parent=projects/*/agent}/sessions/output_contexts"
        };
    };

    rpc ListPlatformsOfAllSessions (ListPlatformsOfAllSessionsRequest) returns (ListPlatformsResponse) {
        option (google.api.http) = {
            get: "/v2/{parent=projects/*/agent}/sessions/platforms"
        };
    };

    rpc ListAccountIdsOfAllSessions (ListAccountIdsOfAllSessionsRequest) returns (ListAccountIdsResponse) {
        option (google.api.http) = {
            get: "/v2/{parent=projects/*/agent}/sessions/account_ids"
        };
    };

    rpc ListPropertyIdsOfAllSessions (ListPropertyIdsOfAllSessionsRequest) returns (ListPropertyIdsResponse) {
        option (google.api.http) = {
            get: "/v2/{parent=projects/*/agent}/sessions/property_ids"
        };
    };

    rpc ListDatastreamIdsOfAllSessions (ListDatastreamIdsOfAllSessionsRequest) returns (ListDatastreamIdsResponse) {
        option (google.api.http) = {
            get: "/v2/{parent=projects/*/agent}/sessions/datastream_ids"
        };
    };


    rpc ListOriginIdsOfAllSessions (ListOriginIdsOfAllSessionsRequest) returns (ListOriginIdsResponse) {
        option (google.api.http) = {
            get: "/v2/{parent=projects/*/agent}/sessions/origin_ids"
        };
    };


    rpc AddSessionLabels (AddSessionLabelsRequest) returns (Session) {
        option (google.api.http) = {
            post: "/v2/{session_id=projects/*/agent/sessions/*}/labels:add"
            body: "*"
        };
    };

    rpc DeleteSessionLabels (DeleteSessionLabelsRequest) returns (Session) {
        option (google.api.http) = {
            post: "/v2/{session_id=projects/*/agent/sessions/*}/labels:delete"
            body: "*"
        };
    };

    rpc AddSessionComment (AddSessionCommentRequest) returns (Comment) {
        option (google.api.http) = {
            post: "/v2/{session_id=projects/*/agent/sessions/*}/comments:add"
            body: "*"
        };
    };

    rpc DeleteSessionComments (DeleteSessionCommentsRequest) returns (Session) {
        option (google.api.http) = {
            post: "/v2/{session_id=projects/*/agent/sessions/*}/comments:delete"
            body: "*"
        };
    };

    rpc UpdateSessionComments (UpdateSessionCommentsRequest) returns (Session) {
        option (google.api.http) = {
            post: "/v2/{session_id=projects/*/agent/sessions/*}/comments:update"
            body: "*"
        };
    };

    rpc ListSessionComments (ListSessionCommentsRequest) returns (ListSessionCommentsResponse) {
        option (google.api.http) = {
            get: "/v2/{session_id=projects/*/agent/sessions/*}/reviews"
        };
    };

    // *** SESSION-REVIEW RELATED ENDPOINTS *** //
    // ListSessionReviews:
    // returns list of session reviews from ondewo-kb; by default only returns session review IDs
    rpc ListSessionReviews (ListSessionReviewsRequest) returns (ListSessionReviewsResponse) {
        option (google.api.http) = {
            get: "/v2/{session_id=projects/*/agent/sessions/*}/reviews"
        };
    };

    // GetSessionReview:
    // returns a session-review from ondewo-kb or computes the first review if none exists
    rpc GetSessionReview (GetSessionReviewRequest) returns (SessionReview) {
        option (google.api.http) = {
            get: "/v2/{session_review_id=projects/*/agent/sessions/*/reviews/*}"
        };
    };

    // GetLatestSessionReview:
    // returns a session-review from ondewo-kb or computes the first review if none exists
    rpc GetLatestSessionReview (GetLatestSessionReviewRequest) returns (SessionReview) {
        option (google.api.http) = {
            get: "/v2/{session_id=projects/*/agent/sessions/*}/reviews:getLatestSessionReview"
        };
    };

    // CreateSessionReview:
    // persist a session review in ondewo-kb
    // as a side effect: also update training data in ondewo-cai
    rpc CreateSessionReview (CreateSessionReviewRequest) returns (SessionReview) {
        option (google.api.http) = {
            post: "/v2/{session_id=projects/*/agent/sessions/*}:createSessionReview"
            body: "*"
        };
    };

    // RPC to get audio files based on specified criteria.
    // Retrieves information about audio files associated with specific sessions.
    // Returns a response containing details of the requested audio files.
    rpc GetAudioFiles (GetAudioFilesRequest) returns (GetAudioFilesResponse) {};

    // RPC to add audio files to a session.
    // Adds new audio files to the specified session, providing details about each file.
    // Returns a response containing information about the added audio files.
    rpc AddAudioFiles (AddAudioFilesRequest) returns (AddAudioFilesResponse) {};

    // RPC to delete specified audio files.
    // Deletes audio files associated with specific sessions based on unique identifiers.
    // Returns an empty response indicating the successful deletion of the specified audio files.
    rpc DeleteAudioFiles (DeleteAudioFilesRequest) returns (DeleteAudioFilesResponse) {};

    // RPC to get a consolidated audio file for a specific session.
    // Retrieves a single audio file that combines all audio files associated with the specified session.
    // Returns details of the consolidated audio file.
    rpc GetAudioFileOfSession (GetAudioFileOfSessionRequest) returns (AudioFileResource) {};

    // RPC to get a list audio files for a specific session.
    // Retrieves a single audio file that combines all audio files associated with the specified session.
    rpc ListAudioFiles (ListAudioFilesRequest) returns (ListAudioFilesResponse) {};

}

// The request to detect user's intent.
message DetectIntentRequest {

    // Required. The name of the session this query is sent to. Format:
    // `projects/&lt;project_uuid&gt;/agent/sessions/&lt;session_uuid&gt;`. It's up to the API
    // caller to choose an appropriate session ID. It can be a random number or
    // some type of user identifier (preferably hashed). The length of the session
    // ID must not exceed 36 bytes.
    string session = 1;

    // Optional. The parameters of this query.
    QueryParameters query_params = 2;

    // Required. The input specification. It can be set to:
    //
    // 1.  an audio config
    //     which instructs the speech recognizer how to process the speech audio,
    //
    // 2.  a conversational query in the form of text, or
    //
    // 3.  an event that specifies which intent to trigger.
    QueryInput query_input = 3;

    // Optional. The natural language speech audio to be processed. This field
    // should be populated iff `query_input` is set to an input audio config.
    // A single request can contain up to 1 minute of speech audio data.
    bytes input_audio = 5;

}

// The message returned from the DetectIntent method.
message DetectIntentResponse {

    // The unique identifier of the response. It can be used to
    // locate a response in the training example set or for reporting issues.
    string response_id = 1;

    // The results of the conversational query or event processing.
    QueryResult query_result = 2;

    // Specifies the status of the webhook request. `webhook_status`
    // is never populated in webhook requests.
    google.rpc.Status webhook_status = 3;
}

// Represents the parameters of the conversational query.
message QueryParameters {

    // Optional. The time zone of this conversational query from the
    // [time zone database](https://www.iana.org/time-zones), e.g.,
    // America/New_York, Europe/Paris. If not provided, the time zone specified in
    // agent settings is used.
    string time_zone = 1;

    // Optional. The geo location of this conversational query.
    google.type.LatLng geo_location = 2;

    // Optional. The collection of contexts to be activated before this query is
    // executed.
    repeated Context contexts = 3;

    // Optional. Specifies whether to delete all contexts in the current session
    // before the new ones are activated.
    bool reset_contexts = 4;

    // Optional. This field can be used to pass custom data into the webhook
    // associated with the agent. Arbitrary JSON objects are supported.
    // key:<pre>language=LanguageCode.de.value</pre>
    // key:<pre>timestamp=time.time()</pre>
    // key:<pre>source='https://ondewo.com'</pre>
    // key:<pre>configuration='config_example_123'</pre>
    google.protobuf.Struct payload = 6;

    // labels associated to this request
    repeated string labels = 7;

    // Only messages for the specified Intent.Message.Platform platforms are sent to the user in the
    // <code>DetectIntentResponse</code>
    repeated Intent.Message.Platform platforms = 8;

    // Id of the account, e.g. Company Ondewo
    string account_id = 9;

    // Id of the property of the account, e.g. Domain ondewo.com
    // This field can also be used for a customized tracking id or tag id
    string property_id = 10;

    // Id of the datastream of the property of the account, e.g. Subdomain sub1.ondewo.com or sub2.ondewo.com
    // This field can also be used for a customized tracking id or tag id
    string datastream_id = 11;

    // Id of the the origin of the user request
    //
    // For a phone bot, this is the phone number +123456789 the user called (Note: This is not the user's phone number)
    // For a chatbot or voicebot on the web, this is the URL on which the bo, e.g. https://ondewo.com/webchat
    // For a voice assistant device, this is the device-id or the app id
    // This field can also be used for a customized tracking id or tag id
    string origin_id = 12; // https://aim-develop.ondewo.com/

    // Id of the "identified user" e.g. for a chatbot the email address or for a phone bot the phone number of the user
    // This field can also be used for a customized tracking id or tag id
    string identified_user_id = 13;

    // transcriptions of the user input sorted by score
    repeated S2tTranscription transcriptions = 14;

}

enum TranscriptionType {

    // unspecified
    TRANSCRIPTION_TYPE_UNSPECIFIED = 0;

    // Automatic transcription by a speech to text system
    TRANSCRIPTION_TYPE_S2T = 1;

    // Manual human transcription
    TRANSCRIPTION_TYPE_HUMAN = 2;
}

// Represents a speech-to-text transcription.
message S2tTranscription {

    // resource name of the transcription
    string name = 1;

    // The transcribed text content.
    string text = 2;

    // Optional. A confidence score associated with the transcription.
    // The score indicates the level of confidence in the accuracy of the transcription.
    // It is a floating-point number, typically ranging from 0.0 (low confidence) to 1.0 (high confidence).
    float score = 3;

    // Optional. The detected language of the transcription.
    // The language is represented by a string following language codes (e.g., "en" for English, "es" for Spanish).
    string language_code = 4;

    // the resource name of the audio file of the transcription
    string audio_resource_name = 5;

    // Optional. pipeline used for transcription. A pipeline ID. Example: "pipeline_1"
    string pipeline_id = 6;

    // Optional. Duration in seconds for transcription
    float duration_in_s = 7;

    // Whether a speech-to-text engine or a human has transcribed the audio
    TranscriptionType transcription_type = 8;

    // Creation date and time. Read-only field.
    google.protobuf.Timestamp created_at = 9;

    // Modification date and time. Read-only field.
    google.protobuf.Timestamp modified_at = 10;

    // User id in form of a valid UUID.
    string created_by = 11;

    // User id in form of a valid UUID.
    string modified_by = 12;

}

// Represents the query input. It can contain either:
//
// 1.  An audio config which
//     instructs the speech recognizer how to process the speech audio.
//
// 2.  A conversational query in the form of text,.
//
// 3.  An event that specifies which intent to trigger.
message QueryInput {

    // Required. The input specification.
    oneof input {

        // Instructs the speech recognizer how to process the speech audio.
        InputAudioConfig audio_config = 1;

        // The natural language text to be processed.
        TextInput text = 2;

        // The event to be processed.
        EventInput event = 3;
    }

    // Files as input for the detect intent request, e.g., image, document, audio, video etc.
    repeated FileResource file_resources = 4;

}

// Represents the result of conversational query or event processing.
message QueryResult {

    // The original conversational query text:
    // - If natural language text was provided as input, `query_text` contains
    //   a copy of the input.
    // - If natural language speech audio was provided as input, `query_text`
    //   contains the speech recognition result. If speech recognizer produced
    //   multiple alternatives, a particular one is picked.
    // - If an event was provided as input, `query_text` is not set.
    string query_text = 1;

    // The Speech recognition confidence between 0.0 and 1.0. A higher number
    // indicates an estimated greater likelihood that the recognized words are
    // correct. The default of 0.0 is a sentinel value indicating that confidence
    // was not set.
    //
    // You should not rely on this field as it isn't guaranteed to be accurate, or
    // even set. In particular this field isn't set in Webhook calls and for
    // StreamingDetectIntent since the streaming endpoint has separate confidence
    // estimates per portion of the audio in StreamingRecognitionResult.
    float speech_recognition_confidence = 2;

    // The action name from the matched intent.
    string action = 3;

    // The collection of extracted parameters.
    google.protobuf.Struct parameters = 4;

    // This field is set to:
    // - `false` if the matched intent has required parameters and not all of
    //    the required parameter values have been collected.
    // - `true` if all required parameter values have been collected, or if the
    //    matched intent doesn't contain any required parameters.
    bool all_required_params_present = 5;

    // The text to be pronounced to the user or shown on the screen.
    string fulfillment_text = 6;

    // The collection of rich messages to present to the user.
    repeated Intent.Message fulfillment_messages = 7;

    // If the query was fulfilled by a webhook call, this field is set to the
    // value of the `source` field returned in the webhook response.
    string webhook_source = 8;

    // If the query was fulfilled by a webhook call, this field is set to the
    // value of the `payload` field returned in the webhook response.
    google.protobuf.Struct webhook_payload = 9;

    // The collection of output contexts. If applicable,
    // `output_contexts.parameters` contains entries with name
    // `<parameter name>.original` containing the original parameter values
    // before the query.
    repeated Context output_contexts = 10;

    // The intent that matched the conversational query. Some, not
    // all fields are filled in this message, including but not limited to:
    // `name`, `display_name` and `webhook_state`.
    Intent intent = 11;

    // The intent detection confidence. Values range from 0.0
    // (completely uncertain) to 1.0 (completely certain).
    float intent_detection_confidence = 12;

    // The user input gets pre-processed by spelling correction, stop word removal etc. This property holds
    // the string that is passed to the entity recognition and intent detection
    string query_text_original = 13;

    // The free-form diagnostic info. For example, this field
    // could contain webhook call latency.
    google.protobuf.Struct diagnostic_info = 14;

    // The language that was triggered during intent detection.
    // See [Language Support](https://dialogflow.com/docs/reference/language)
    // for a list of the currently supported language codes.
    string language_code = 15;

    // Generated or attached files, e.g., llm generates a picture or file attachment
    repeated FileResource file_resources = 16;

}


// The top-level message sent by the client to the
// `StreamingDetectIntent` method.
//
// Multiple request messages should be sent in order:
//
// 1.  The first message must contain `session`, `query_input` plus optionally
//     `query_params` and/or `single_utterance`. The message must not contain `input_audio`.
//
// 2.  If `query_input` was set to a streaming input audio config,
//     all subsequent messages must contain only `input_audio`.
//     Otherwise, finish the request stream.
message StreamingDetectIntentRequest {

    // Required. The name of the session the query is sent to.
    // Format of the session name:
    // `projects/&lt;project_uuid&gt;/agent/sessions/&lt;session_uuid&gt;`. It’s up to the API
    // caller to choose an appropriate &lt;session_uuid&gt;. It can be a random number or
    // some type of user identifier (preferably hashed). The length of the session
    // ID must not exceed 36 characters.
    string session = 1;

    // Optional. The parameters of this query.
    QueryParameters query_params = 2;

    // Required. The input specification. It can be set to:
    //
    // 1.  an audio config which instructs the speech recognizer how to process
    //     the speech audio,
    //
    // 2.  a conversational query in the form of text, or
    //
    // 3.  an event that specifies which intent to trigger.
    QueryInput query_input = 3;

    // Optional. If `false` (default), recognition does not cease until the
    // client closes the stream.
    // If `true`, the recognizer will detect a single spoken utterance in input
    // audio. Recognition ceases when it detects the audio's voice has
    // stopped or paused. In this case, once a detected intent is received, the
    // client should close the stream and start a new request with a new stream as
    // needed.
    // This setting is ignored when `query_input` is a piece of text or an event.
    bool single_utterance = 4;

    // Optional. The input audio content to be recognized. Must be sent if
    // `query_input` was set to a streaming input audio config. The complete audio
    // over all streaming messages must not exceed 1 minute.
    bytes input_audio = 6;

}

// The top-level message returned from the
// `StreamingDetectIntent` method.
//
// Multiple response messages can be returned in order:
//
// 1.  If the input was set to streaming audio, the first one or more messages
//     contain `recognition_result`. Each `recognition_result` represents a more
//     complete transcript of what the user said. The last `recognition_result`
//     has `is_final` set to `true`.
//
// 2.  The next message contains `response_id`, `query_result`
//     and optionally `webhook_status` if a WebHook was called.
message StreamingDetectIntentResponse {

    // The unique identifier of the response. It can be used to
    // locate a response in the training example set or for reporting issues.
    string response_id = 1;

    // The result of speech recognition.
    StreamingRecognitionResult recognition_result = 2;

    // The result of the conversational query or event processing.
    QueryResult query_result = 3;

    // Specifies the status of the webhook request.
    google.rpc.Status webhook_status = 4;

}

// Contains a speech recognition result corresponding to a portion of the audio
// that is currently being processed or an indication that this is the end
// of the single requested utterance.
//
// Example:
//
// 1.  transcript: "tube"
//
// 2.  transcript: "to be a"
//
// 3.  transcript: "to be"
//
// 4.  transcript: "to be or not to be"
//     is_final: true
//
// 5.  transcript: " that's"
//
// 6.  transcript: " that is"
//
// 7.  recognition_event_type: `RECOGNITION_EVENT_END_OF_SINGLE_UTTERANCE`
//
// 8.  transcript: " that is the question"
//     is_final: true
//
// Only two of the responses contain final results (#4 and #8 indicated by
// `is_final: true`). Concatenating these generates the full transcript: "to be
// or not to be that is the question".
//
// In each response we populate:
//
// *  for `MESSAGE_TYPE_TRANSCRIPT`: `transcript` and possibly `is_final`.
//
// *  for `MESSAGE_TYPE_END_OF_SINGLE_UTTERANCE`: only `event_type`.
message StreamingRecognitionResult {

    // Type of the response message.
    enum MessageType {
        // Not specified. Should never be used.
        MESSAGE_TYPE_UNSPECIFIED = 0;

        // Message contains a (possibly partial) transcript.
        TRANSCRIPT = 1;

        // Event indicates that the server has detected the end of the user's speech
        // utterance and expects no additional speech. Therefore, the server will
        // not process additional audio (although it may subsequently return
        // additional results). The client should stop sending additional audio
        // data, half-close the gRPC connection, and wait for any additional results
        // until the server closes the gRPC connection. This message is only sent if
        // `single_utterance` was set to `true`, and is not used otherwise.
        END_OF_SINGLE_UTTERANCE = 2;
    }

    // Type of the result message.
    MessageType message_type = 1;

    // Transcript text representing the words that the user spoke.
    // Populated if and only if `event_type` = `RECOGNITION_EVENT_TRANSCRIPT`.
    string transcript = 2;

    // The default of 0.0 is a sentinel value indicating `confidence` was not set.
    // If `false`, the `StreamingRecognitionResult` represents an
    // interim result that may change. If `true`, the recognizer will not return
    // any further hypotheses about this piece of the audio. May only be populated
    // for `event_type` = `RECOGNITION_EVENT_TRANSCRIPT`.
    bool is_final = 3;

    // The Speech confidence between 0.0 and 1.0 for the current portion of audio.
    // A higher number indicates an estimated greater likelihood that the
    // recognized words are correct. The default of 0.0 is a sentinel value
    // indicating that confidence was not set.
    //
    // This field is typically only provided if `is_final` is true and you should
    // not rely on it being accurate or even set.
    float confidence = 4;

}

// Instructs the speech recognizer how to process the audio content.
message InputAudioConfig {

    // Required. Audio encoding of the audio content to process.
    AudioEncoding audio_encoding = 1;

    // Required. Sample rate (in Hertz) of the audio content sent in the query.
    // Refer to [Cloud Speech API documentation](/speech/docs/basics) for more
    // details.
    int32 sample_rate_hertz = 2;

    // Required. The language of the supplied audio. Dialogflow does not do
    // translations. See [Language
    // Support](https://dialogflow.com/docs/languages) for a list of the
    // currently supported language codes. Note that queries in the same session
    // do not necessarily need to specify the same language.
    string language_code = 3;

    // Optional. The collection of phrase hints which are used to boost accuracy
    // of speech recognition.
    // Refer to [Cloud Speech API documentation](/speech/docs/basics#phrase-hints)
    // for more details.
    repeated string phrase_hints = 4;
}

// Represents the natural language text to be processed.
message TextInput {

    // Required. The UTF-8 encoded natural language text to be processed.
    // Text length must not exceed 256 bytes.
    string text = 1;

    // Required. The language of this conversational query. See [Language
    // Support](https://dialogflow.com/docs/languages) for a list of the
    // currently supported language codes. Note that queries in the same session
    // do not necessarily need to specify the same language.
    string language_code = 2;
}

// Events allow for matching intents by event name instead of the natural
// language input. For instance, input `<event: { name: “welcome_event”,
// parameters: { name: “Sam” } }>` can trigger a personalized welcome response.
// The parameter `name` may be used by the agent in the response:
// `“Hello #welcome_event.name! What can I do for you today?”`.
message EventInput {

    // Required. The unique identifier of the event.
    string name = 1;

    // Optional. The collection of parameters associated with the event.
    google.protobuf.Struct parameters = 2;

    // Required. The language of this query. See [Language
    // Support](https://dialogflow.com/docs/languages) for a list of the
    // currently supported language codes. Note that queries in the same session
    // do not necessarily need to specify the same language.
    string language_code = 3;
}

// Audio encoding of the audio content sent in the conversational query request.
// Refer to the [Cloud Speech API documentation](/speech/docs/basics) for more
// details.
enum AudioEncoding {

    // Not specified.
    AUDIO_ENCODING_UNSPECIFIED = 0;

    // Uncompressed 16-bit signed little-endian samples (Linear PCM).
    AUDIO_ENCODING_LINEAR_16 = 1;

    // [`FLAC`](https://xiph.org/flac/documentation.html) (Free Lossless Audio
    // Codec) is the recommended encoding because it is lossless (therefore
    // recognition is not compromised) and requires only about half the
    // bandwidth of `LINEAR16`. `FLAC` stream encoding supports 16-bit and
    // 24-bit samples, however, not all fields in `STREAMINFO` are supported.
    AUDIO_ENCODING_FLAC = 2;

    // 8-bit samples that compand 14-bit audio samples using G.711 PCMU/mu-law.
    AUDIO_ENCODING_MULAW = 3;

    // Adaptive Multi-Rate Narrowband codec. `sample_rate_hertz` must be 8000.
    AUDIO_ENCODING_AMR = 4;

    // Adaptive Multi-Rate wideband codec. `sample_rate_hertz` must be 16000.
    AUDIO_ENCODING_AMR_WB = 5;

    // Opus encoded audio frames in Ogg container
    // ([OggOpus](https://wiki.xiph.org/OggOpus)).
    // `sample_rate_hertz` must be 16000.
    AUDIO_ENCODING_OGG_OPUS = 6;

    // Although the use of lossy encodings is not recommended, if a very low
    // bitrate encoding is required, `OGG_OPUS` is highly preferred over
    // Speex encoding. The [Speex](https://speex.org/) encoding supported by
    // Dialogflow API has a header byte in each block, as in MIME type
    // `audio/x-speex-with-header-byte`.
    // It is a variant of the RTP Speex encoding defined in
    // [RFC 5574](https://tools.ietf.org/html/rfc5574).
    // The stream is a sequence of blocks, one block per RTP packet. Each block
    // starts with a byte containing the length of the block, in bytes, followed
    // by one or more frames of Speex data, padded to an integral number of
    // bytes (octets) as specified in RFC 5574. In other words, each RTP header
    // is replaced with a single byte containing the block length. Only Speex
    // wideband is supported. `sample_rate_hertz` must be 16000.
    AUDIO_ENCODING_SPEEX_WITH_HEADER_BYTE = 7;
}

// *** SESSION RELATED MESSAGES *** //

// Session of a user interaction
message Session {

    // The unique identifier of the session
    // Format: <pre><code>projects/&lt;project_uuid&gt;/agent/sessions/&lt;session_uuid&gt;</code></pre>
    string name = 1;

    // The list of all the steps of the session
    repeated SessionStep session_steps = 2;

    // session information
    SessionInfo session_info = 3;

    // Represents the options for views of a session.
    // A session can be a sizable object. Therefore, we provide a resource view that
    // does not return all data
    enum View {

        // Endpoints decide whether to return the full or the sparse view
        VIEW_UNSPECIFIED = 0;

        // All fields are populated.
        VIEW_FULL = 1;

        // Only some fields are populated in the response.
        VIEW_SPARSE = 2;
    }

    // Creation date and time. Read-only field.
    google.protobuf.Timestamp created_at = 4;

    // Modification date and time. Read-only field.
    google.protobuf.Timestamp modified_at = 5;

    // User id in form of a valid UUID.
    string created_by = 6;

    // User id in form of a valid UUID.
    string modified_by = 7;

}

// SessionStep is a single user interaction as part of a session
message SessionStep {

    // The unique identifier for the given review
    // Format: <pre><code>projects/&lt;project_uuid&gt;/agent/sessions/&lt;session_uuid&gt;/sessionsteps/&lt;session_step_uuid&gt;</code></pre>
    string name = 1;

    // The detect intent request of the session step
    DetectIntentRequest detect_intent_request = 2;

    // The detect intent response  of the session step
    DetectIntentResponse detect_intent_response = 3;

    // The contexts which were active at the beginning of this step
    repeated Context contexts = 4;

    // Timestamp of session step
    google.protobuf.Timestamp timestamp = 5;

    // Creation date and time. Read-only field.
    google.protobuf.Timestamp created_at = 6;

    // Modification date and time. Read-only field.
    google.protobuf.Timestamp modified_at = 7;

    // User id in form of a valid UUID.
    string created_by = 8;

    // User id in form of a valid UUID.
    string modified_by = 9;

    // audio file resources associated with the session step
    repeated AudioFileResource audio_file_resources = 10;

}

// This message is a request to get a session step
message GetSessionStepRequest {

    // The unique identifier for the given session step
    // Format: <pre><code>projects/&lt;project_uuid&gt;/agent/sessions/&lt;session_uuid&gt;/sessionsteps/&lt;session_step_uuid&gt;
    string name = 1;

    // Optional. The mask to control which fields will be filled with data.
    // Example: path=["session_step.detect_intent_response.query_result.fulfillment_messages"]
    google.protobuf.FieldMask field_mask = 2;

}

// UpdateSessionStepRequest stores a session step into the session
message UpdateSessionStepRequest {

    // The session step to be updated
    SessionStep session_step = 1;

    // Optional. The mask to control which fields will be updated.
    // Example: path=["session_step.detect_intent_response.query_result.fulfillment_messages"]
    google.protobuf.FieldMask update_mask = 2;

    // Optional. The mask to control which fields will be filled with data.
    // Example: path=["session_step.detect_intent_response.query_result.fulfillment_messages"]
    google.protobuf.FieldMask field_mask = 3;

}

// This message is a request to delete a session step of a session
message DeleteSessionStepRequest {

    // The unique identifier for the given session step
    // Format: <pre><code>projects/&lt;project_uuid&gt;/agent/sessions/&lt;session_uuid&gt;/sessionsteps/&lt;session_step_uuid&gt;</code></pre>.
    string name = 1;

}

// CreateSessionStepRequest stores a session step into the session
message CreateSessionStepRequest {

    // The unique identifier for the given review
    // Format: <pre><code>projects/&lt;project_uuid&gt;/agent/sessions/&lt;session_uuid&gt;/sessionsteps/&lt;session_step_uuid&gt;</code></pre>.
    string session_id = 1;

    // The session step to be added
    SessionStep session_step = 2;

    // field mask specifying what the request should return, e.g. only name, created_at etc.
    google.protobuf.FieldMask field_mask = 3;

}

// This message is a request to list sessions
message ListSessionsRequest {

    // Required. The project that the agent to fetch is associated with.
    // Format: <pre><code>projects/&lt;project_uuid&gt;/agents</code></pre>
    string parent = 1;

    // An enum specifying the amount of information to be returned per session
    Session.View session_view = 2;

    // Optional: The page token to support pagination.
    // Pagination allows you to retrieve a large result set in smaller, more manageable portions.
    // The page token is a string representing the current index and page size.
    //
    // Valid page token strings:
    // * "" (empty string) - Retrieves the first page.
    // * "current_index-0--page_size-20" - Retrieves the first page with a page size of 20.
    // * "current_index-1--page_size-20" - Retrieves the second page with a page size of 20.
    //
    // Index starts at 0.
    //
    // Examples of valid page token strings:
    // * ""
    // * "current_index-0--page_size-20"
    // * "current_index-1--page_size-20"
    // * "current_index-10--page_size-20"
    //
    // Examples of invalid page token strings:
    // * "1"
    // * "current_index-0--page_size-20"
    // * "current_index--1--page_size-20"
    // * "current_index1--page_size-20"
    // * "current_index-1--page_size--20"
    string page_token = 4;

    // Optional. A filter to narrow the response down to sessions of interest.
    SessionFilter session_filter = 5;

    // Optional. The mask to control which fields will be filled with data.
    // Example: path=["session_info.duration_in_s_min"]
    google.protobuf.FieldMask field_mask = 6;
}

// Message used to filter sessions based on contextual information
message ContextFilter {

    // name of the context
    string context_name = 1;

    // name of the key of the context parameter
    string key = 2;

    // value of the parameter
    string value = 3;

    ComparisonOperator operator = 4;
}

// Type of operator to compare
enum ComparisonOperator {

    // equal operator
    EQUAL = 0;

    // greater operator, e.g. for numbers, dates, and strings
    GREATER = 1;

    // greater or equal operator, e.g. for numbers, dates, and strings
    GREATER_OR_EQUAL = 2;

    // less or equal operator, e.g. for numbers, dates, and strings
    LESS_OR_EQUAL = 3;

    // contains operator, e.g. part of string, or one of the elements in an iterable such as set or list
    CONTAINS = 4;

    // starts with operator for string comparison only
    STARTS_WITH = 5;

    // ends with operator for string comparison only
    ENDS_WITH = 6;
}

// This message contains a session filter
message SessionFilter {

    // A SessionFilter can be used in some requests to return only sessions matching certain filter conditions.
    // All fields below are optional. Multiple fields specified at the same time are chained via AND.
    // Match only sessions with all of the following language_codes
    repeated string language_codes = 1;

    // Match only sessions during which all of the following intents were detected
    // NOTE: only name and display name fields are used for comparison
    repeated Intent matched_intents = 2;

    // Match only sessions during which all of the following entity types were recognized
    // NOTE: only name and display name fields are used for comparison
    repeated EntityType matched_entity_types = 3;

    // Match only sessions where the minimum confidence for intent detection along the session falls
    // in the following range. Defaults to -1 if not set.
    float min_intents_confidence_min = 4;

    // Match only sessions where the minimum confidence for intent detection along the session falls
    // in the following range. Defaults to +1 if not set.
    float min_intents_confidence_max = 5;

    // Match only sessions where the minimum confidence for entity recognition along the session falls
    //  in the following range. Defaults to -1 if not set.
    float min_entity_types_confidence_min = 6;

    // Match only sessions where the minimum confidence for entity recognition along the session falls
    //  in the following range. Defaults to +1 if not set.
    float min_entity_types_confidence_max = 7;

    // Match only sessions whose time range falls within the following range (in UNIX epochs).
    // Defaults to 0 if not set.
    double earliest = 8;

    // Match only sessions whose time range falls within the following range (in UNIX epochs).
    // Defaults to current epoch if not set
    double latest = 9;

    // Match only sessions for which the number of turns (interaction steps) falls in the following range
    // Defaults to 0 if not set.
    int32 min_number_turns = 10;

    // Match only sessions for which the number of turns (interaction steps) falls in the following range
    // Defaults to MAXINT if not set.
    int32 max_number_turns = 11;

    // Match only session which have all of the following labels assigned
    repeated string labels = 12;

    // Match only session which had all of the following user_ids interacting with them.
    repeated string user_ids = 13;

    // Match only session which have all of the following intent tags assigned
    repeated string intent_tags = 14;

    // Match only sessions whose IDs are specified here
    repeated string session_ids = 15;

    // Match only sessions whose session info contains at least one step having all the contexts specified here
    // The input contexts are pre-conditions for detecting intents
    repeated Context input_contexts = 16;

    // The output contexts are the result of the intent matching and track the contextual state of a conversation
    repeated Context output_contexts = 17;

    // Match only sessions for which the duration in seconds are larger or equal
    float duration_in_s_min = 18;

    // Match only sessions for which the duration in seconds are smaller or equal
    float duration_in_s_max = 19;

    // Match only sessions for which the duration in minutes are larger or equal
    float duration_in_m_min = 20;

    // Match only sessions for which the duration in minutes are smaller or equal
    float duration_in_m_max = 21;

    // Match only sessions for which the duration in minutes rounded are larger or equal
    float duration_in_m_rounded_min = 22;

    // Match only sessions for which the duration in minutes rounded are smaller or equal
    float duration_in_m_rounded_max = 23;

    // Match only sessions for which the duration in 15 seconds rounded are larger or equal
    float duration_interval_15s_rounded_min = 24;

    // Match only sessions for which the duration in 15 seconds rounded are smaller or equal
    float duration_interval_15s_rounded_max = 25;

    // Match only sessions for which the duration in 30 seconds rounded are larger or equal
    float duration_interval_30s_rounded_min = 26;

    // Match only sessions for which the duration in 30 seconds rounded are smaller or equal
    float duration_interval_30s_rounded_max = 27;

    // Match only sessions for which the duration in 45 seconds rounded are larger or equal
    float duration_interval_45s_rounded_min = 28;

    // Match only sessions for which the duration in 45 seconds rounded are smaller or equal
    float duration_interval_45s_rounded_max = 29;

    // Match only sessions for which the started_time_slot_per_hour (e.g. 08:00) are larger or equal
    string started_time_slot_per_hour_min = 30;

    // Match only sessions for which the started_time_slot_per_hour (e.g. 14:00) are smaller or equal
    string started_time_slot_per_hour_max = 31;

    // Match only sessions for which the started_time_slot_per_quarter_hour (e.g. 08:00) are larger or equal
    string started_time_slot_per_quarter_hour_min = 32;

    // Match only sessions for which the started_time_slot_per_quarter_hour (e.g. 14:00) are smaller or equal
    string started_time_slot_per_quarter_hour_max = 33;

    // Match only sessions for which the started_time_slot_per_half_hour (e.g. 08:00) are larger or equal
    string started_time_slot_per_half_hour_min = 34;

    // Match only sessions for which the started_time_slot_per_half_hour (e.g. 14:00) are smaller or equal
    string started_time_slot_per_half_hour_max = 35;

    // Match only sessions for which the started_time_slot_per_day_phase (e.g. 08:00) are larger or equal
    string started_time_slot_per_day_phase_min = 36;

    // Match only sessions for which the started_time_slot_per_day_phase (e.g. 14:00) are smaller or equal
    string started_time_slot_per_day_phase_max = 37;

    // Match only sessions for which the started_time_slot_per_minute (e.g. 08:00) are larger or equal
    string started_time_slot_per_minute_min = 38;

    // Match only sessions for which the started_time_slot_per_minute (e.g. 14:00) are smaller or equal
    string started_time_slot_per_minute_max = 39;

    // Match only sessions for which the duration in seconds rounded are larger or equal
    float duration_in_s_rounded_min = 40;

    // Match only sessions for which the duration in seconds rounded are smaller or equal
    float duration_in_s_rounded_max = 41;

    // Messages for each of the Intent.Message.Platform were sent to the user
    repeated Intent.Message.Platform platforms = 42;

    // Ids of the account, e.g. Company Ondewo,
    // This field can also be used for customized tracking ids or tag ids
    repeated string account_ids = 43;

    // Ids of the property of the account, e.g. Domain ondewo.com
    // This field can also be used for customized tracking ids or tag ids
    repeated string property_ids = 44;

    // Ids of the datastream of the property of the account, e.g. Subdomain sub1.ondewo.com or sub2.ondewo.com
    // This field can also be used for customized tracking ids or tag ids
    repeated string datastream_ids = 45;

    // Ids of the the origin of the user request
    //
    // For a phone bot, this is the phone number +123456789 the user called (Note: This is not the user's phone number)
    // For a chatbot or voicebot on the web, this is the URL on which the bo, e.g. https://ondewo.com/webchat
    // For a voice assistant device, this is the device-id or the app id
    repeated string origin_ids = 46;

    // Ids of the "identified user" e.g. for a chatbot the email address or for a phone bot the phone number of the user
    repeated string identified_user_ids = 47;

    // Match only sessions for which the duration in 60 seconds rounded are larger or equal
    float duration_interval_60s_rounded_min = 48;

    // Match only sessions for which the duration in 60 seconds rounded are smaller or equal
    float duration_interval_60s_rounded_max = 49;
}

// This message contains information about session
message SessionInfo {

    // A SessionInfo contains some general information about a session.
    //
    // This information can be returned inside a Session object for consumption by a client.
    // Or it can be used by the backend to check whether the Session matches a given SessionFilter.
    //
    // All fields below are optional. Multiple fields specified at the same time are chained
    // The language codes used in the given session.
    repeated string language_codes = 1;

    // A list of intents which have been matched
    repeated Intent matched_intents = 2;

    // A list of entity types which have been matched
    repeated EntityType matched_entity_types = 3;

    // The minimum confidence for intent recognition along the session
    float min_intents_confidence = 4;

    // The minimum confidence for entity recognition along the session
    float min_entity_types_confidence = 5;

    // The earliest date of the given session (in UNIX epochs), i.e. the time of the first interaction of a user
    // in the given session
    double earliest = 6;

    // The latest date of the given session (in UNIX epochs), i.e. the time of the last interaction of a user
    // in the given session
    double latest = 7;

    // The number of turns (interaction steps) in the given session
    int32 number_turns = 8;

    // The list of labels of the given session
    repeated string labels = 9;

    // The user_ids of the users which were interacting within the given session
    repeated string user_ids = 10;

    // The list of intent tags in the given session
    repeated string intent_tags = 11;

    // The list of contexts of each step collected in an outer list
    message ContextSteps {

        repeated Context contexts = 1;
    }

    // The input contexts that are matched in the given session. The name of the context here is the short name
    // and not the full URL name including the project parent
    repeated ContextSteps input_context_steps = 12;

    // The output contexts that are matched in the given session. The name of the context here is the short name
    // and not the full URL name including the project parent
    repeated ContextSteps output_context_steps = 13;

    //  duration in seconds
    float duration_in_s = 14;

    // duration in minutes
    float duration_in_m = 15;

    // duration in minutes rounded
    float duration_in_m_rounded = 16;

    // duration in 15 seconds intervals rounded
    float duration_interval_15s_rounded = 17;

    // duration in 30 seconds intervals rounded
    float duration_interval_30s_rounded = 18;

    // duration in 45 seconds intervals rounded
    float duration_interval_45s_rounded = 19;

    // started_time_slot_per_hour (e.g. 08:00)
    string started_time_slot_per_hour = 20;

    // started_time_slot_per_quarter_hour (e.g. 08:00)
    string started_time_slot_per_quarter_hour = 21;

    // started_time_slot_per_half_hour (e.g. 08:00)
    string started_time_slot_per_half_hour = 22;

    // started_time_slot_per_day_phase (e.g. 14:00)
    string started_time_slot_per_day_phase = 23;

    // started_time_slot_per_minute (e.g. 14:00)
    string started_time_slot_per_minute = 24;

    // duration in seconds rounded
    float duration_in_s_rounded = 25;

    // Messages for each of the Intent.Message.Platform were sent to the user
    repeated Intent.Message.Platform platforms = 26;

    // Ids of the account, e.g. Company Ondewo,
    // This field can also be used for customized tracking ids or tag ids
    repeated string account_ids = 27;

    // Ids of the property of the account, e.g. Domain ondewo.com
    // This field can also be used for customized tracking ids or tag ids
    repeated string property_ids = 28;

    // Ids of the datastream of the property of the account, e.g. Subdomain sub1.ondewo.com or sub2.ondewo.com
    // This field can also be used for customized tracking ids or tag ids
    repeated string datastream_ids = 29;

    // Ids of the the origin of the user request
    //
    // For a phone bot, this is the phone number +123456789 the user called (Note: This is not the user's phone number)
    // For a chatbot or voicebot on the web, this is the URL on which the bo, e.g. https://ondewo.com/webchat
    // For a voice assistant device, this is the device-id or the app id
    repeated string origin_ids = 30;

    // Ids of the "identified user" e.g. for a chatbot the email address or for a phone bot the phone number of the user
    repeated string identified_user_ids = 31;

    // duration in 60 seconds intervals rounded
    float duration_interval_60s_rounded = 32;

    // comments about a session
    repeated Comment parent_comment = 33;

}

// This message is a response including the listing of sessions
message ListSessionsResponse {

    // The requested sessions
    repeated Session sessions = 1;

    // The next_page_token is used to retrieve the next page of a returned result,
    // e.g. next_page_token is current_index-2
    string next_page_token = 2;
}

// This message is a request to get a session
message GetSessionRequest {
    // The session to be returned
    // Format: <pre><code>projects/&lt;project_uuid&gt;/agent/sessions/&lt;session_uuid&gt;</code></pre>
    string session_id = 1;

    // whether to return a full or sparse view; if unspecified full view is returned
    Session.View session_view = 2;

    // Optional. The mask to control which fields will be filled with data.
    // Example: path=["session_info.duration_in_s_min"]
    google.protobuf.FieldMask field_mask = 6;
}

// This message is a request to create a session
message CreateSessionRequest {

    // Required. The project that the agent to fetch is associated with.
    // Format: <pre><code>projects/&lt;project_uuid&gt;/agents</code></pre>
    string parent = 1;

    // The unique UUID of a Session
    // Format: UUID Version 4, e.g. 2f59fad2-06bc-4730-9920-d3148f28f357
    string session_uuid = 2; // Optional. If not provided, it will be auto-generated

    // Optional. labels for the session.
    repeated string labels = 3;

    // Optional. The collection of contexts to be activated before this query is executed.
    repeated Context contexts = 4;
}

// This message is a request to delete a session
message DeleteSessionRequest {

    // Required. The session to be deleted
    // Format: <pre><code>projects/&lt;project_uuid&gt;/agent/sessions/&lt;session_uuid&gt;</code></pre>
    string session_id = 1;
}

// *** SESSION-REVIEW RELATED MESSAGES *** //
message CreateSessionReviewRequest {

    // The unique identifier for the session under review
    // Format: <pre><code>projects/&lt;project_uuid&gt;/agent/sessions/&lt;session_uuid&gt;</code></pre>
    string session_id = 1;

    // Optional: The unique identifier of the parent review
    // Format: <pre><code>projects/&lt;project_uuid&gt;/agent/sessions/&lt;session_uuid&gt;/reviews/&lt;session_review_uuid&gt;</code></pre>
    string parent_review_id = 2;

    // The reviews for all steps in the session
    SessionReview session_review = 3;

    SessionReview.View session_review_view = 4;
}

// This message contains a session review
message SessionReview {

    // The unique identifier for the given review
    // Format: <pre><code>projects/&lt;project_uuid&gt;/agent/sessions/&lt;session_uuid&gt;/reviews/&lt;session_review_uuid&gt;</code></pre>
    string name = 1;

    // The reviews for all steps in the session
    repeated SessionReviewStep session_review_steps = 2;

    // Represents the options for views of a session_review.
    // A session_review can be a sizable object. Therefore, we provide a resource view that
    // does not return all data
    enum View {
        // Endpoints decide whether to return the full or the sparse view
        VIEW_UNSPECIFIED = 0;

        // All fields are populated.
        VIEW_FULL = 1;

        // Only some fields are populated in the response.
        VIEW_SPARSE = 2;
    }

    // Creation date and time. Read-only field.
    google.protobuf.Timestamp created_at = 3;

    // Modification date and time. Read-only field.
    google.protobuf.Timestamp modified_at = 4;

    // User id in form of a valid UUID.
    string created_by = 5;

    // User id in form of a valid UUID.
    string modified_by = 6;

}

// This message contains a session review step
message SessionReviewStep {

    // The unique identifier for the given review step
    // Format: <pre><code>projects/&lt;project_uuid&gt;/agent/sessions/&lt;session_uuid&gt;/reviews/&lt;review_uuid&gt;/sessionreviewsteps/&lt;session_review_step_uuid&gt;</code></pre>
    string name = 1;

    // The user says with markup of the detected entity types after the preprocessing such as spelling correction,
    // stopword removal etc. has been applied.
    //
    // This string represents what has been passed to the entity recognition and intent detection algorithms.
    Intent.TrainingPhrase annotated_usersays = 2;

    // The language code
    string language_code = 3;

    // Unique detected intents ordered by descending confidence
    repeated DetectedIntent detected_intents = 4;

    // The contexts which were active at the beginning of this step
    repeated Context contexts = 5;

    // The output contexts of this step
    repeated Context contexts_out = 6;

    // User input without any pre-processing applied
    string query_text_original = 7;

    // Messages for each of the Intent.Message.Platform were sent to the user
    repeated Intent.Message.Platform platforms = 8;

    // Timestamp of session review step
    google.protobuf.Timestamp timestamp = 9;

    // Creation date and time. Read-only field.
    google.protobuf.Timestamp created_at = 10;

    // Modification date and time. Read-only field.
    google.protobuf.Timestamp modified_at = 11;

    // User id in form of a valid UUID.
    string created_by = 12;

    // User id in form of a valid UUID.
    string modified_by = 13;

    // audio file resources associated with the session review step
    repeated AudioFileResource audio_file_resources = 14;

}


// This message contains a detected intent
message DetectedIntent {

    // intent
    Intent intent = 1;

    // score of intent detection
    float score = 2;

    // intent detection algorithm
    string algorithm = 3;

    // collection of rich messages to present to the user
    // This field is set only for the first detected intent. For the rest of the intents the messages are not
    //   resolved and the raw messages for the current language code are available in self.intent.messages
    repeated Intent.Message fulfillment_messages = 4;

    // This field is set to:
    // - `true` if the matched intent has required parameters and not all of
    //    the required parameter values have been collected.
    // - `false` if all required parameter values have been collected, or if the
    //    matched intent doesn't contain any required parameters.
    bool required_param_missing = 5;
}

// This message is a request to list session labels
message ListSessionLabelsRequest {

    // The id of the session
    string session_id = 1;
}

// request to list all labels of all sessions
message ListSessionLabelsOfAllSessionsRequest {

    // The parent for which the labels for all sessions should be listed
    // Format: <pre><code>projects/&lt;project_uuid&gt;/agent</code></pre>
    string parent = 1;

    // Optional. A filter to narrow the response down to sessions of interest.
    SessionFilter session_filter = 2;
}

// This message is a response of listing session labels
message ListSessionLabelsResponse {

    // The labels of the session
    repeated string labels = 1;
}

// request to list all language codes of all sessions
message ListLanguageCodesOfAllSessionsRequest {

    // The parent for which the language_codes for all sessions should be listed
    // Format: <pre><code>projects/&lt;project_uuid&gt;/agent</code></pre>
    string parent = 1;

    // Optional. A filter to narrow the response down to sessions of interest.
    SessionFilter session_filter = 2;
}

// This message is a response of listing session language_codes
message ListLanguageCodesResponse {

    // The language_codes of the session
    repeated string language_codes = 1;
}



// request to list all matched_intents of all sessions
message ListMatchedIntentsOfAllSessionsRequest {

    // The parent for which the matched_intents for all sessions should be listed
    // Format: <pre><code>projects/&lt;project_uuid&gt;/agent</code></pre>
    string parent = 1;

    // Optional. A filter to narrow the response down to sessions of interest.
    SessionFilter session_filter = 2;
}

// This message is a response of listing session matched_intents
message ListMatchedIntentsResponse {

    // The matched_intents of the session
    repeated string matched_intents = 1;
}


// request to list all matched_entity_types of all sessions
message ListMatchedEntityTypesOfAllSessionsRequest {

    // The parent for which the matched_entity_types for all sessions should be listed
    // Format: <pre><code>projects/&lt;project_uuid&gt;/agent</code></pre>
    string parent = 1;

    // Optional. A filter to narrow the response down to sessions of interest.
    SessionFilter session_filter = 2;
}

// This message is a response of listing session matched_entity_types
message ListMatchedEntityTypesResponse {

    // The matched_entity_types of the session
    repeated string matched_entity_types = 1;
}


// request to list all user_ids of all sessions
message ListUserIdsOfAllSessionsRequest {

    // The parent for which the user_ids for all sessions should be listed
    // Format: <pre><code>projects/&lt;project_uuid&gt;/agent</code></pre>
    string parent = 1;

    // Optional. A filter to narrow the response down to sessions of interest.
    SessionFilter session_filter = 2;
}

// This message is a response of listing session user_ids
message ListUserIdsResponse {

    // The user_ids of the session
    repeated string user_ids = 1;
}


// request to list all identified_user_ids of all sessions
message ListIdentifiedUserIdsOfAllSessionsRequest {

    // The parent for which the identified_user_ids for all sessions should be listed
    // Format: <pre><code>projects/&lt;project_uuid&gt;/agent</code></pre>
    string parent = 1;

    // Optional. A filter to narrow the response down to sessions of interest.
    SessionFilter session_filter = 2;
}

// This message is a response of listing session identified_user_ids
message ListIdentifiedUserIdsResponse {

    // The identified_user_ids of the session
    repeated string identified_user_ids = 1;
}


// request to list all tags of all sessions
message ListTagsOfAllSessionsRequest {

    // The parent for which the tags for all sessions should be listed
    // Format: <pre><code>projects/&lt;project_uuid&gt;/agent</code></pre>
    string parent = 1;

    // Optional. A filter to narrow the response down to sessions of interest.
    SessionFilter session_filter = 2;
}

// This message is a response of listing session tags
message ListTagsResponse {

    // The tags of the session
    repeated string tags = 1;
}


// request to list all input_contexts of all sessions
message ListInputContextsOfAllSessionsRequest {

    // The parent for which the input_contexts for all sessions should be listed
    // Format: <pre><code>projects/&lt;project_uuid&gt;/agent</code></pre>
    string parent = 1;

    // Optional. A filter to narrow the response down to sessions of interest.
    SessionFilter session_filter = 2;
}

// This message is a response of listing session input_contexts
message ListInputContextsResponse {

    // The input_contexts ids of the session
    repeated string input_contexts = 1;
}


// request to list all output_contexts of all sessions
message ListOutputContextsOfAllSessionsRequest {

    // The parent for which the output_contexts for all sessions should be listed
    // Format: <pre><code>projects/&lt;project_uuid&gt;/agent</code></pre>
    string parent = 1;

    // Optional. A filter to narrow the response down to sessions of interest.
    SessionFilter session_filter = 2;
}

// This message is a response of listing session output_contexts
message ListOutputContextsResponse {

    // The output_contexts ids of the session
    repeated string output_contexts = 1;
}


// request to list all labels of all sessions
message ListPlatformsOfAllSessionsRequest {

    // The parent for which the platforms for all sessions should be listed
    // Format: <pre><code>projects/&lt;project_uuid&gt;/agent</code></pre>
    string parent = 1;

    // Optional. A filter to narrow the response down to sessions of interest.
    SessionFilter session_filter = 2;
}

// This message is a response of listing session platforms
message ListPlatformsResponse {

    // The platforms of the session
    repeated string platforms = 1;
}


// request to list all account_ids of all sessions
message ListAccountIdsOfAllSessionsRequest {

    // The parent for which the account_ids for all sessions should be listed
    // Format: <pre><code>projects/&lt;project_uuid&gt;/agent</code></pre>
    string parent = 1;

    // Optional. A filter to narrow the response down to sessions of interest.
    SessionFilter session_filter = 2;
}

// This message is a response of listing session account_ids
message ListAccountIdsResponse {

    // The account_ids of the session
    repeated string account_ids = 1;
}


// request to list all property_ids of all sessions
message ListPropertyIdsOfAllSessionsRequest {

    // The parent for which the property_ids for all sessions should be listed
    // Format: <pre><code>projects/&lt;project_uuid&gt;/agent</code></pre>
    string parent = 1;

    // Optional. A filter to narrow the response down to sessions of interest.
    SessionFilter session_filter = 2;
}

// This message is a response of listing session property_ids
message ListPropertyIdsResponse {

    // The property_ids of the session
    repeated string property_ids = 1;
}

// request to list all datastream_ids of all sessions
message ListDatastreamIdsOfAllSessionsRequest {

    // The parent for which the datastream_ids for all sessions should be listed
    // Format: <pre><code>projects/&lt;project_uuid&gt;/agent</code></pre>
    string parent = 1;

    // Optional. A filter to narrow the response down to sessions of interest.
    SessionFilter session_filter = 2;
}

// This message is a response of listing session datastream_ids
message ListDatastreamIdsResponse {

    // The datastream_ids of the session
    repeated string datastream_ids = 1;
}

// request to list all origin_ids of all sessions
message ListOriginIdsOfAllSessionsRequest {

    // The parent for which the origin_ids for all sessions should be listed
    // Format: <pre><code>projects/&lt;project_uuid&gt;/agent</code></pre>
    string parent = 1;

    // Optional. A filter to narrow the response down to sessions of interest.
    SessionFilter session_filter = 2;
}

// This message is a response of listing session origin_ids
message ListOriginIdsResponse {

    // The origin_ids of the session
    repeated string origin_ids = 1;
}

// This message is a request to add session labels
message AddSessionLabelsRequest {

    // The id of the session
    string session_id = 1;

    // The labels to add to the session
    repeated string labels = 2;
}

// This message is a request to delete session labels
message DeleteSessionLabelsRequest {

    // The id of the session
    string session_id = 1;

    // The labels to delete from the session
    repeated string labels = 2;
}

// This message is a request to add a comment to a session
message AddSessionCommentRequest {

    // The id of the session
    string session_id = 1;

    // The comment to add to the session
    Comment comment = 2;
}

// This message is a request to delete a session comment
message DeleteSessionCommentsRequest {

    // The id of the session
    string session_id = 1;

    // The comment names to delete from the session
    repeated string comment_names = 2;

}

// This message is a request to update a session comment
message UpdateSessionCommentsRequest {

    // The id of the session
    string session_id = 1;

    // The comment of a session to be updated
    Comment comment = 2;
}

// This message is a request to list comments of a session
message ListSessionCommentsRequest {

    // The unique identifier for the session for which reviews should be listed
    // Format: <pre><code>projects/&lt;project_uuid&gt;/agent/sessions/&lt;session_uuid&gt;</code></pre>
    string session_id = 1;

    // Optional: The page token to support pagination.
    // Pagination allows you to retrieve a large result set in smaller, more manageable portions.
    // The page token is a string representing the current index and page size.
    //
    // Valid page token strings:
    // * "" (empty string) - Retrieves the first page.
    // * "current_index-0--page_size-20" - Retrieves the first page with a page size of 20.
    // * "current_index-1--page_size-20" - Retrieves the second page with a page size of 20.
    //
    // Index starts at 0.
    //
    // Examples of valid page token strings:
    // * ""
    // * "current_index-0--page_size-20"
    // * "current_index-1--page_size-20"
    // * "current_index-10--page_size-20"
    //
    // Examples of invalid page token strings:
    // * "1"
    // * "current_index-0--page_size-20"
    // * "current_index--1--page_size-20"
    // * "current_index1--page_size-20"
    // * "current_index-1--page_size--20"
    string page_token = 2;
}

// This message is a request to list comments of a session
message ListSessionCommentsResponse {

    // The comments of a specific session
    // Format: <pre><code>projects/&lt;project_uuid&gt;/agent/sessions/&lt;session_uuid&gt;/comments/&lt;comment_uuid&gt;</code></pre>
    repeated Comment comment = 1;

    // Optional: The page token to support pagination.
    // Pagination allows you to retrieve a large result set in smaller, more manageable portions.
    // The page token is a string representing the current index and page size.
    //
    // Valid page token strings:
    // * "" (empty string) - Retrieves the first page.
    // * "current_index-0--page_size-20" - Retrieves the first page with a page size of 20.
    // * "current_index-1--page_size-20" - Retrieves the second page with a page size of 20.
    //
    // Index starts at 0.
    //
    // Examples of valid page token strings:
    // * ""
    // * "current_index-0--page_size-20"
    // * "current_index-1--page_size-20"
    // * "current_index-10--page_size-20"
    //
    // Examples of invalid page token strings:
    // * "1"
    // * "current_index-0--page_size-20"
    // * "current_index--1--page_size-20"
    // * "current_index1--page_size-20"
    // * "current_index-1--page_size--20"
    string page_token = 2;

}

// This message is a request to list session reviews
message ListSessionReviewsRequest {

    // The unique identifier for the session for which reviews should be listed
    // Format: <pre><code>projects/&lt;project_uuid&gt;/agent/sessions/&lt;session_uuid&gt;</code></pre>
    string session_id = 1;

    // An enum specifying the amount of information to be returned per session review
    SessionReview.View session_review_view = 2;

    // Optional: The page token to support pagination.
    // Pagination allows you to retrieve a large result set in smaller, more manageable portions.
    // The page token is a string representing the current index and page size.
    //
    // Valid page token strings:
    // * "" (empty string) - Retrieves the first page.
    // * "current_index-0--page_size-20" - Retrieves the first page with a page size of 20.
    // * "current_index-1--page_size-20" - Retrieves the second page with a page size of 20.
    //
    // Index starts at 0.
    //
    // Examples of valid page token strings:
    // * ""
    // * "current_index-0--page_size-20"
    // * "current_index-1--page_size-20"
    // * "current_index-10--page_size-20"
    //
    // Examples of invalid page token strings:
    // * "1"
    // * "current_index-0--page_size-20"
    // * "current_index--1--page_size-20"
    // * "current_index1--page_size-20"
    // * "current_index-1--page_size--20"
    string page_token = 4;
}

// This message is a response of listing session reviews
message ListSessionReviewsResponse {

    // The requested session reviews
    repeated SessionReview session_reviews = 1;

    // The next_page_token is used to retrieve the next page of a returned result,
    // e.g. next_page_token is current_index-2
    string next_page_token = 2;
}

// This message is a request to get session review
message GetSessionReviewRequest {

    // The unique identifier of the session review to be returned
    string session_review_id = 1;

    SessionReview.View session_review_view = 2;
}

// This message is a request to get latest session review
message GetLatestSessionReviewRequest {

    // The unique identifier of the session for which the latest review should be returned
    // Format: <pre><code>projects/&lt;project_uuid&gt;/agent/sessions/&lt;session_uuid&gt;</code></pre>
    string session_id = 1;

    // An enum specifying the amount of information to be returned for the desired session review
    SessionReview.View session_review_view = 2;
}

// Represents the options for views of resources.
enum ResourceView {

    // Resource view not specified
    RESOURCE_VIEW_UNSPECIFIED = 0;

    // All fields are populated including bytes e.g., for audio files
    RESOURCE_VIEW_FULL = 1;

    // Fields include metadata but no bytes
    RESOURCE_VIEW_PARTIAL = 2;

    // Minimum view only without bytes and metadata
    RESOURCE_VIEW_MINIMUM = 3;
}

// File type of an audio resource
enum AudioFileResourceType {

    // Unspecified audio file type
    AUDIO_FILE_RESOURCE_TYPE_UNSPECIFIED = 0;

    // Audio file from text to speech
    AUDIO_FILE_RESOURCE_TYPE_T2S = 1;

    // Audio file from speech to text
    AUDIO_FILE_RESOURCE_TYPE_S2T = 2;

    // Audio file from speech to text and text to speech
    AUDIO_FILE_RESOURCE_TYPE_S2T_AND_T2S = 3;

}

// Represents a file resource that can either be an image, audio, document, or video file.
message FileResource {

    // Oneof to specify either an image, audio, document, or video file resource.
    // Only one of the file types will be set at a time.
    oneof file_resource {

        // Document file resource (e.g., markdown, text, word, powerpoint, pdf, excel etc.).
        DocumentFileResource document_file_resource = 1;

        // An audio file resource, such as a recording or sound file.
        AudioFileResource audio_file_resource = 2;

        // An image file resource, such as a JPEG, PNG, etc.
        ImageFileResource image_file_resource = 3;

        // A video file resource, such as an MP4 or AVI file.
        VideoFileResource video_file_resource = 4;

    }

}

// Represents a document file resource (e.g., text, markdown, PDF, DOCX).
message DocumentFileResource {

    // The unique identifier for the document file resource.
    // Format: <pre><code>projects/&lt;project_uuid&gt;/agent/sessions/&lt;session_uuid&gt;/documents/&lt;document_uuid&gt;</code></pre>
    string name = 1;

    // The display name of the document file, which can be the file name (e.g., "report.pdf")
    // or a user-assigned name.
    string display_name = 2;

    // The raw bytes of the document file (e.g., PDF, DOCX, TXT).
    bytes bytes = 3;

    // Creation date and time of the document file. This is a read-only field.
    google.protobuf.Timestamp created_at = 4;

    // The last modification date and time of the document file. This is a read-only field.
    google.protobuf.Timestamp modified_at = 5;

    // The UUID of the user who created the document file.
    string created_by = 6;

    // The UUID of the user who last modified the document file.
    string modified_by = 7;

}

message ImageFileResource {

    // The unique identifier of the session for which the latest review should be returned
    // Format: <pre><code>projects/&lt;project_uuid&gt;/agent/sessions/&lt;session_uuid&gt;/images/&lt;image_uuid&gt;</code></pre>
    string name = 1;

    // File name of the image, e.g., MyPicture.jpg, or a user assigned display name
    string display_name = 2;

    // Bytes of the audio file
    bytes bytes = 3;

    // Creation date and time. Read-only field.
    google.protobuf.Timestamp created_at = 4;

    // Modification date and time. Read-only field.
    google.protobuf.Timestamp modified_at = 5;

    // User id in form of a valid UUID.
    string created_by = 6;

    // User id in form of a valid UUID.
    string modified_by = 7;

}

message AudioFileResource {

    // The unique identifier of the session for which the latest review should be returned
    // Format: <pre><code>projects/&lt;project_uuid&gt;/agent/sessions/&lt;session_uuid&gt;/audios/&lt;audio_uuid&gt;</code></pre>
    string name = 1;

    // Bytes of the audio file
    bytes bytes = 2;

    // Language of the audio file
    string language = 3;

    // Duration in seconds and milliseconds of the audio file
    float duration_in_s = 4;

    // sample rate of the audio
    int32 sample_rate = 5;

    // File type of an audio resource
    AudioFileResourceType audio_file_resource_type = 6;

    // transcriptions of the user input sorted by score.
    // A transcription can be from a speech-to-text system or a human
    repeated S2tTranscription transcriptions = 7;

    // Creation date and time. Read-only field.
    google.protobuf.Timestamp created_at = 8;

    // Modification date and time. Read-only field.
    google.protobuf.Timestamp modified_at = 9;

    // User id in form of a valid UUID.
    string created_by = 10;

    // User id in form of a valid UUID.
    string modified_by = 11;

    // Bytes of the audio file
    string display_name = 12;

}

// Represents a video file resource (e.g., MP4, AVI).
message VideoFileResource {

    // The unique identifier for the video file resource.
    // Format: <pre><code>projects/&lt;project_uuid&gt;/agent/sessions/&lt;session_uuid&gt;/videos/&lt;video_uuid&gt;</code></pre>
    string name = 1;

    // The display name of the video file, which can be a user-assigned label.
    string display_name = 2;

    // The raw bytes representing the video file (e.g., MP4, AVI).
    bytes bytes = 3;

    // The duration of the video file in seconds.
    float duration_in_s = 4;

    // The resolution of the video (e.g., "1920x1080" for Full HD).
    string resolution = 5;

    // The frame rate of the video (e.g., 30 fps).
    float frame_rate = 6;

    // Creation date and time of the video file. This is a read-only field.
    google.protobuf.Timestamp created_at = 7;

    // The last modification date and time of the video file. This is a read-only field.
    google.protobuf.Timestamp modified_at = 8;

    // The UUID of the user who created the video file.
    string created_by = 9;

    // The UUID of the user who last modified the video file.
    string modified_by = 10;

}

// This message is a request to get audio files specified
message GetAudioFilesRequest {

    // Required. The project of this agent.
    // Format: <pre><code>projects/&lt;project_uuid&gt;/agent</code></pre>
    string parent = 1;

    // The unique identifier of the audio file of the specific session
    // Format: <pre><code>projects/&lt;project_uuid&gt;/agent/sessions/&lt;session_uuid&gt;/audios/&lt;audio_uuid&gt;</code></pre>
    repeated string names = 2;

    // Represents the options for views of resources
    ResourceView resource_view = 3;

    // Optional: The page token to support pagination.
    // Pagination allows you to retrieve a large result set in smaller, more manageable portions.
    // The page token is a string representing the current index and page size.
    //
    // Valid page token strings:
    // * "" (empty string) - Retrieves the first page.
    // * "current_index-0--page_size-20" - Retrieves the first page with a page size of 20.
    // * "current_index-1--page_size-20" - Retrieves the second page with a page size of 20.
    //
    // Index starts at 0.
    //
    // Examples of valid page token strings:
    // * ""
    // * "current_index-0--page_size-20"
    // * "current_index-1--page_size-20"
    // * "current_index-10--page_size-20"
    //
    // Examples of invalid page token strings:
    // * "1"
    // * "current_index-0--page_size-20"
    // * "current_index--1--page_size-20"
    // * "current_index1--page_size-20"
    // * "current_index-1--page_size--20"
    string page_token = 4;

    // sorting mode
    SortingMode sorting_mode = 5;

}

// This message is a request to retrieve the audio files specified
message GetAudioFilesResponse {

    // The unique identifier of the audio file for a specific session.
    // Format: <pre><code>projects/&lt;project_uuid&gt;/agent/sessions/&lt;session_uuid&gt;/audios/&lt;audio_uuid&gt;</code></pre>
    repeated AudioFileResource audio_files = 1;

    // error message if there are any.
    string error_message = 2;

    // The next_page_token is used to retrieve the next page of a returned result,
    // e.g. next_page_token is current_index-2
    string next_page_token = 3;

}

// This message is a request to add the audio files specified
message AddAudioFilesRequest {

    // Required. The project of this agent.
    // Format: <pre><code>projects/&lt;project_uuid&gt;/agent</code></pre>
    string parent = 1;

    // The unique identifier of the session for which the audio files should be listed
    // Format: <pre><code>projects/&lt;project_uuid&gt;/agent/sessions/&lt;session_uuid&gt;/&lt</code></pre>
    string session_id = 2;

    // AudioFileResources to be added
    repeated AudioFileResource audio_file_resources = 3;

    // The unique identifier of the session step for which the audio files should be listed
    // Format: <pre><code>projects/&lt;project_uuid&gt;/agent/sessions/&lt;session_uuid&gt;/sessionsteps/&lt;session_step_uuid&gt;/&lt</code></pre>
    string session_step_id = 4;

}

// This message is a request to add the audio files specified
message AddAudioFilesResponse {

    // The unique identifier of the audio files for a specific session.
    // Format: <pre><code>projects/&lt;project_uuid&gt;/agent/sessions/&lt;session_uuid&gt;/audios/&lt;audio_uuid&gt;</code></pre>
    repeated AudioFileResource audio_file_resources = 1;

    // error message if there are any.
    string error_message = 2;

}

// This message is a request to the delete audio files specified
message DeleteAudioFilesRequest {

    // Required. The project of this agent.
    // Format: <pre><code>projects/&lt;project_uuid&gt;/agent</code></pre>
    string parent = 1;

    // The unique identifier of the audio file of the specific session
    // Format: <pre><code>projects/&lt;project_uuid&gt;/agent/sessions/&lt;session_uuid&gt;/audios/&lt;audio_uuid&gt;</code></pre>
    repeated string names = 2;

}

// This message is a request to the delete audio files specified
message DeleteAudioFilesResponse {

    // The unique identifier of the audio file of the specific session
    // Format: <pre><code>projects/&lt;project_uuid&gt;/agent/sessions/&lt;session_uuid&gt;/audios/&lt;audio_uuid&gt;</code></pre>
    repeated string names = 1;

    // error message if there are any.
    string error_message = 2;

}

// This message is a request to list all available audio files of a session
message ListAudioFilesRequest {

    // Required. The project of this agent.
    // Format: <pre><code>projects/&lt;project_uuid&gt;/agent</code></pre>
    string parent = 1;

    // Optional: The unique identifier of the session for which the audio files should be listed
    // Format: <pre><code>projects/&lt;project_uuid&gt;/agent/sessions/&lt;session_uuid&gt;/&lt</code></pre>
    string session_id = 2;

    // Represents the options for views of resources
    ResourceView resource_view = 3;

    // Optional: The page token to support pagination.
    // Pagination allows you to retrieve a large result set in smaller, more manageable portions.
    // The page token is a string representing the current index and page size.
    //
    // Valid page token strings:
    // * "" (empty string) - Retrieves the first page.
    // * "current_index-0--page_size-20" - Retrieves the first page with a page size of 20.
    // * "current_index-1--page_size-20" - Retrieves the second page with a page size of 20.
    //
    // Index starts at 0.
    //
    // Examples of valid page token strings:
    // * ""
    // * "current_index-0--page_size-20"
    // * "current_index-1--page_size-20"
    // * "current_index-10--page_size-20"
    //
    // Examples of invalid page token strings:
    // * "1"
    // * "current_index-0--page_size-20"
    // * "current_index--1--page_size-20"
    // * "current_index1--page_size-20"
    // * "current_index-1--page_size--20"
    string page_token = 4;

    // sorting mode
    SortingMode sorting_mode = 5;

}

// This message is a request to retrieve the audio files specified
message ListAudioFilesResponse {

    // The requested audio files .
    // Format: <pre><code>projects/&lt;project_uuid&gt;/agent/sessions/&lt;session_uuid&gt;/audios/&lt;audio_uuid&gt;</code></pre>
    repeated AudioFileResource audio_files = 1;

    // The next_page_token is used to retrieve the next page of a returned result,
    // e.g. next_page_token is current_index-2
    string next_page_token = 2;

    // error message if there are any.
    string error_message = 3;

}


// This message is a request to get one one file combining all audios of a specific session
message GetAudioFileOfSessionRequest {

    // Required. The project of this agent.
    // Format: <pre><code>projects/&lt;project_uuid&gt;/agent</code></pre>
    string parent = 1;

    // The unique identifier of the session for which the audio files should be combined
    // Format: <pre><code>projects/&lt;project_uuid&gt;/agent/sessions/&lt;session_uuid&gt;/&lt</code></pre>
    string session_id = 2;

    // Represents the options for views of resources
    ResourceView resource_view = 3;

}
